{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17801916",
   "metadata": {},
   "source": [
    "# AE2 - The Colour Language Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d6eb8",
   "metadata": {},
   "source": [
    "#### Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections as col \n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import networkx as nx\n",
    "import collections as col\n",
    "from collections import Counter\n",
    "import webcolors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae81a41",
   "metadata": {},
   "source": [
    "#### Cleaning color database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsDF = pd.read_csv('colour_naming_data.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Renaming unlabled columns\n",
    "newColumnNames = {\n",
    "    'Unnamed: 1': 'Color Name',\n",
    "    'Unnamed: 2': 'Red',\n",
    "    'Unnamed: 3': 'Green',\n",
    "    'Unnamed: 4':'Blue'\n",
    "}\n",
    "colorsDF = colorsDF.rename(columns=newColumnNames)\n",
    "\n",
    "# Dropping reference lines\n",
    "colorsDF = colorsDF.drop(colorsDF.index[:4], axis=0)\n",
    "\n",
    "# Removing Sample ID Column\n",
    "colorsDF = colorsDF.drop(colorsDF.columns[0], axis=1)\n",
    "\n",
    "# Removing whitespace, making lowercase, and removing special characters\n",
    "colorsDF = colorsDF.applymap(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.strip().lower()) if isinstance(x, str) else x)\n",
    "\n",
    "# Change RGB values to int\n",
    "columnsToConvert = ['Red', 'Green', 'Blue']\n",
    "colorsDF[columnsToConvert] = colorsDF[columnsToConvert].astype(int)\n",
    "\n",
    "# Concentrate on main hue component by removing adjectives\n",
    "def removeColorAdjectives(text):\n",
    "    colorAdjectives = ['pale', 'vivid', 'soft', 'muted', 'very', 'saturated','grass', 'deep', 'appale', 'dull']  \n",
    "    pattern = r'\\b(?:' + '|'.join(colorAdjectives) + r')\\b\\s*'\n",
    "    cleanedText = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    return cleanedText\n",
    "\n",
    "colorsDF['Color Name'] = colorsDF['Color Name'].apply(removeColorAdjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bab5c6",
   "metadata": {},
   "source": [
    "#### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2Distance(color1, color2):\n",
    "    \"\"\"\n",
    "    Euclidean distance between colors\n",
    "    \"\"\"\n",
    "    assert len(color1) == len(color2) == 3, \"Color tuples misarranged\"\n",
    "    \n",
    "    return math.sqrt((color1[0]-color2[0]) ** 2 + (color1[1] - color2[1]) ** 2 + (color1[2] - color2[2])**2)\n",
    "\n",
    "\n",
    "def findCentroid(color):\n",
    "    \"\"\"\n",
    "    Returns averaged RGB tuple of given color\n",
    "    \"\"\"\n",
    "    # Take only the specific color subset of dataframe\n",
    "    colorValues = colorsDF[colorsDF['Color Name'] == color]\n",
    "    # find the centroid (average RGB values of given color)\n",
    "    averageValues = tuple(colorValues[['Red', 'Green', 'Blue']].mean())\n",
    "    return averageValues\n",
    "\n",
    "\n",
    "def isColor(string):\n",
    "    \"\"\"\n",
    "    Returns true if a given color is in the webcolors database, false if not\n",
    "    \"\"\"\n",
    "    try:\n",
    "        webcolors.name_to_rgb(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def threeDToTwoD(colorCoord):\n",
    "    \"\"\"\n",
    "    Converts a 3 dimensional list or tuple into 2 dimensions\n",
    "    \"\"\"\n",
    "    return (colorCoord[0]/colorCoord[2], colorCoord[1]/colorCoord[2])\n",
    "\n",
    "def isCorrectColor(color, colorRGB, threshold):\n",
    "    \"\"\"\n",
    "    Returns true if the distance between a color and its centroid is below a certain threshold, false if not\n",
    "    \"\"\"\n",
    "    dist = L2Distance(colorRGB, findCentroid(color))\n",
    "    return dist <= threshold\n",
    "\n",
    "def rgbListToColorList(model, rgbVals):\n",
    "    \"\"\"\n",
    "    Creates a list of guesses with a KNN model converting rgb values to color names\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    for color in rgbVals:\n",
    "        RGBValuesScaled = scaler.transform(np.array(color).reshape(1,-1)) \n",
    "        predictedColor = model.predict(RGBValuesScaled)\n",
    "        guesses.append(predictedColor)\n",
    "    guesses = [guess[0] for guess in guesses]\n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2717dff",
   "metadata": {},
   "source": [
    "#### Alice Picking Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6177bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandomColor():\n",
    "    \"\"\"\n",
    "    Returns a tuple of 3 values between 0-255\n",
    "    \"\"\"\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    \n",
    "aliceTestColors = [generateRandomColor() for _ in range(10)]\n",
    "\n",
    "print(\"Alice has chosen the following colors:\")\n",
    "for i, color in enumerate(aliceTestColors):\n",
    "    print(f\"Color {i+1}: {color}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee0c9c",
   "metadata": {},
   "source": [
    "#### Bob Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231c6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Pull out rgb data and color name answers\n",
    "X = colorsDF[['Red', 'Green', 'Blue']]  # Features: RGB values\n",
    "y = colorsDF['Color Name']  # Target labels: Color names\n",
    "\n",
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "def totalDistance(k):\n",
    "    \"\"\"\n",
    "    Returns the total euclidean distance between centriods and 100 randomly generating colors\n",
    "    \"\"\"\n",
    "    testColors = [generateRandomColor() for _ in range(100)]\n",
    "    \n",
    "    # train the model based on k parameter\n",
    "    knnModel = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnModel.fit(X_scaled, y)\n",
    "    \n",
    "    guesses = rgbListToColorList(knnModel, testColors)\n",
    "    \n",
    "    totalDistance = 0.0\n",
    "    centriods = [findCentroid(color) for color in guesses]\n",
    "    for i, col in enumerate(guesses):\n",
    "        if any(isinstance(x, float) and math.isnan(x) for x in centriods[i]): # NAN check\n",
    "            continue\n",
    "        else:\n",
    "            totalDistance += L2Distance(testColors[i], centriods[i])\n",
    "    \n",
    "    return totalDistance\n",
    "\n",
    "\n",
    "def bestK():\n",
    "    \"\"\"\n",
    "    Returns best value for K based on the the one which gives the \n",
    "    lowest total distance between colors and their centriods.\n",
    "    Secondly, returns the list of summed distances computed for each K\n",
    "    \"\"\"\n",
    "    bestDistance = float('inf')\n",
    "    bestK = -1\n",
    "    distancesList = []\n",
    "    for i in range(1, 13):\n",
    "        distancesList.append(totalDistance(i))\n",
    "    bestK = distancesList.index(min(distancesList))\n",
    "    return bestK+1, distancesList\n",
    "    \n",
    "\n",
    "# Train classifier with best K\n",
    "bestKValue = bestK()[0]  # Use best value of K (tends to be 3)\n",
    "knnModel = KNeighborsClassifier(n_neighbors=bestKValue)\n",
    "knnModel.fit(X_scaled, y)\n",
    "\n",
    "# Compute KNN (Bob's) guesses\n",
    "bobGuesses = []\n",
    "\n",
    "for color in aliceTestColors:\n",
    "    new_rgb_values_scaled = scaler.transform(np.array(color).reshape(1,-1))  # Scale the new data\n",
    "    predicted_color = knnModel.predict(new_rgb_values_scaled)\n",
    "    bobGuesses.append(predicted_color)\n",
    "    \n",
    "print(\"Hi, I'm Bob. Here's what I think those colors are: \")\n",
    "for i, color in enumerate(bobGuesses):\n",
    "    print(f\"Color {i+1} is {color[0]}\")\n",
    "    \n",
    "def displayColors(rgbValues, colorNames, boxWidth = 2):\n",
    "    \"\"\"\n",
    "    Prints squares of colors and their name above them\n",
    "    \"\"\"\n",
    "    \n",
    "    numColors = len(rgbValues)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(numColors * boxWidth, 1))\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    for i in range(numColors):\n",
    "        color = tuple(val / 255 for val in rgbValues[i])  # Normalize RGB values\n",
    "        name = colorNames[i][0].title()\n",
    "        \n",
    "        ax.text(i + 0.5, 1, name, ha='center')\n",
    "        ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=color))\n",
    "    \n",
    "    ax.set_xlim(0, numColors)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "displayColors(aliceTestColors, bobGuesses)\n",
    "print('\\n')\n",
    "\n",
    "def colorScatterPlot(rgbValues, colorNames):\n",
    "    \"\"\"\n",
    "    Prints a 3D scatter plot from rgb values labeled with color names\n",
    "    \"\"\"\n",
    "    # Convert RGB values to floats between 0 and 1\n",
    "    rgbFloat = np.array(rgbValues) / 255.0\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(rgbFloat[:, 0], rgbFloat[:, 1], rgbFloat[:, 2], c=rgbFloat, s=500)\n",
    "\n",
    "    # Add labels to each point\n",
    "    for i, txt in enumerate(colorNames):\n",
    "        ax.text(rgbFloat[i, 0], rgbFloat[i, 1], rgbFloat[i, 2], txt, color='black', fontsize=12)\n",
    "\n",
    "    ax.set_xlabel('Red')\n",
    "    ax.set_ylabel('Green')\n",
    "    ax.set_zlabel('Blue')\n",
    "    ax.set_title('RGB Scatter Plot with Color Labels)')\n",
    "\n",
    "    # Make the plot interactive\n",
    "    plt.show()\n",
    "    \n",
    "colorScatterPlot(aliceTestColors, bobGuesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d638f2",
   "metadata": {},
   "source": [
    "#### Evaluating Bob's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69423d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "\n",
    "def accuracy(model, testColors, threshold = 80, nFolds = 10):\n",
    "    \"\"\"\n",
    "    Returns mean accuracy for model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the testing colors\n",
    "    testColors = []\n",
    "    for i in range(nFolds):\n",
    "        testColors.extend([generateRandomColor() for _ in range(20)])\n",
    "    \n",
    "    # Generate color guesses\n",
    "    guesses = rgbListToColorList(knnModel, testColors)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    totalGuesses = len(testColors)\n",
    "    correctGuesses = 0\n",
    "\n",
    "    for rgbVal, color in zip(testColors, guesses):\n",
    "        if isCorrectColor(color, rgbVal, threshold):\n",
    "            correctGuesses +=1\n",
    "    \n",
    "    return (correctGuesses/totalGuesses) * 100\n",
    "\n",
    "def classificationMetrics(predictions, groundTruth, color):\n",
    "    \"\"\"\n",
    "    Calculates true positives and negatives and false positives and negatives\n",
    "    \"\"\"\n",
    "    TP = sum(1 for pred, gt in zip(predictions, groundTruth) if pred == color and gt == color)\n",
    "    TN = sum(1 for pred, gt in zip(predictions, groundTruth) if pred != color and gt != color)\n",
    "    FP = sum(1 for pred, gt in zip(predictions, groundTruth) if pred == color and gt != color)\n",
    "    FN = sum(1 for pred, gt in zip(predictions, groundTruth) if pred != color and gt == color)\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def precisionCalc(rgbColorList, colorNameList, groundTruths):\n",
    "    \"\"\"\n",
    "    Returns average precision of color set \n",
    "    \"\"\"\n",
    "    \n",
    "    total = 0\n",
    "    uniqueColors = set(colorNameList)\n",
    "    for color in uniqueColors:\n",
    "        TP, TN, FP, FN = classificationMetrics(colorNameList, groundTruths, color)\n",
    "        total += TP/(TP + FP)\n",
    "    \n",
    "    return total/len(uniqueColors)\n",
    "\n",
    "def recallCalc(rgbColorList, colorNameList, groundTruths):\n",
    "    \"\"\"\n",
    "    Returns the recall score\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    \n",
    "    uniqueColors = set(colorNameList)\n",
    "    for color in uniqueColors:\n",
    "        TP, TN, FP, FN = classificationMetrics(colorNameList, groundTruths, color)\n",
    "        if (TP + FN) > 0:\n",
    "            total += TP / (TP + FN)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return total/len(uniqueColors)\n",
    "\n",
    "def f1Calc(precision, recall):\n",
    "    \"\"\"\n",
    "    Returns f1 score\n",
    "    \"\"\"\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Start printing evals\n",
    "\n",
    "# Getting a consistent testset with rgb values and color names\n",
    "testColors = [generateRandomColor() for _ in range(100)]\n",
    "\n",
    "guesses = rgbListToColorList(knnModel, testColors)\n",
    "\n",
    "# create the list of ground truths to determine accuracy \n",
    "groundTruths = [colorName if isCorrectColor(colorName, colorRGB, 70) else 'xxx' \n",
    "                for colorRGB, colorName in zip(testColors, guesses)]\n",
    "\n",
    "print(f\"Bob's mean accuracy was: {accuracy(knnModel, testColors)}%\")\n",
    "precision = precisionCalc(testColors, guesses, groundTruths)\n",
    "print(f\"Bob's precision was: {precision*100:.2f}%\")\n",
    "recall = recallCalc(testColors, guesses, groundTruths)\n",
    "print(f\"Bob's recall was: {recall*100:.2f}%\")\n",
    "print(f\"Bob's f1-score was: {f1Calc(precision, recall)*100:.2f}%\")\n",
    "\n",
    "# Visualizing\n",
    "\n",
    "# Values for K\n",
    "x = range(1, 13)\n",
    "\n",
    "# list of all summed euclidian distances for each k value 1-12. It is metric 1\n",
    "distances = bestK()[1]\n",
    "\n",
    "# list of accuracy scores for each k, it is metric 2\n",
    "acc = []\n",
    "\n",
    "# list of f1 scores for each k, it is metric 3\n",
    "f1 = []\n",
    "\n",
    "# Calculates metrics for K 1-12\n",
    "for i in range(1,13):\n",
    "    variousKModel = KNeighborsClassifier(n_neighbors=i)\n",
    "    variousKModel.fit(X_scaled, y)\n",
    "    newGuesses = rgbListToColorList(variousKModel, testColors)\n",
    "    prec = precisionCalc(testColors, newGuesses, groundTruths)\n",
    "    recall = recallCalc(testColors, newGuesses, groundTruths)\n",
    "    acc.append(accuracy(variousKModel, testColors))\n",
    "    f1.append(f1Calc(prec, recall)*100)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot the first line with thousands on the left y-axis\n",
    "sns.lineplot(x=x, y=distances, ax=ax1, label='Total Distance from Centroids', color='blue')\n",
    "ax1.set_ylabel('Y-axis (Line 1)', color='blue')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the other lines with tens on the right y-axis\n",
    "sns.lineplot(x=x, y=acc, ax=ax2, label='Accuracy', color='green')\n",
    "sns.lineplot(x=x, y=f1, ax=ax2, label='F1-Score', color='red')\n",
    "ax2.set_ylabel('Y-axis (Lines 2 and 3)', color='black')\n",
    "\n",
    "plt.title('K Values vs Various Metrics')\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \"\"\"Graph class, for an undirected, unweighted graph with an adjacency list representation\n",
    "        For an edge A-B, it appears in the adjaency list as A-B and B-A\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, V = [], E = []):\n",
    "        \"\"\" Create a new graph from a list of verticies V and edges E.\n",
    "        By default, the graph is undirected \"\"\"\n",
    "        self.G = {}\n",
    "\n",
    "        for v in V:\n",
    "            self.add_vertex(v)\n",
    "        for u, v in E:\n",
    "            self.add_edge(u, v)\n",
    "            \n",
    "    def add_vertex(self, v):\n",
    "        if v not in self.G:\n",
    "            self.G[v] = set()\n",
    "        \n",
    "    def add_edge(self, u, v):\n",
    "        # add vertices in case they don't already exist\n",
    "        self.add_vertex(u)\n",
    "        self.add_vertex(v)\n",
    "\n",
    "        # add undirected edge (u,v)\n",
    "        self.G[u].add(v)\n",
    "        self.G[v].add(u)\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, v):\n",
    "        \"\"\" Return all vertices adjacent to v (overriding index operator!)\"\"\"\n",
    "        return self.G.get(v, set())\n",
    "\n",
    "    def bfs_spanning_tree(self, start):\n",
    "        \"\"\" Find the breadth-first search spanning tree\n",
    "        This algorithm uses the double-ended queue collection class \"\"\"\n",
    "        span = DirectedGraph(V=[start])\n",
    "        Q = col.deque() # Use the built-in double-ended queue\n",
    "        Q.appendleft(start)\n",
    "        visited = {start}\n",
    "        \n",
    "        while len(Q)>0: # while Q is not empty\n",
    "            current = Q.pop()\n",
    "            adj = self.G[current]  # find vertices adjacent to current node\n",
    "            for v in adj:          # for each vertice, if they are not yet visited, add a spanning edge\n",
    "                if v not in visited:\n",
    "                    Q.appendleft(v)\n",
    "                    visited.add(v)\n",
    "                    span.add_edge(current,v)\n",
    "        \n",
    "        return span\n",
    "    \n",
    "    def shortest_path(self, start, end):\n",
    "        \"\"\" Find the shortest path from start to end. This implementation is not the most efficient.\n",
    "        It first finds the BFS spanning tree, reverses all of the edges in the BFS tree then\n",
    "        walks from the end to the start to determine the shortest path in the original graph. \"\"\"\n",
    "        bfs = self.bfs_spanning_tree(start) # creates a digraph\n",
    "        rev = bfs.reverse()\n",
    "        path = rev.walk(end, start)\n",
    "        return path\n",
    "\n",
    "    def __repr__(self):\n",
    "        graph_str = ''\n",
    "        for v in self.G:\n",
    "            graph_str += '['+v+'] => ' + str(self[v]) + '\\n'\n",
    "        return graph_str\n",
    "\n",
    "    def is_adjacent(self,u,v):\n",
    "        \"\"\" Test if u and v are adjacent \"\"\"\n",
    "        return v in self[u] and u in self[v]\n",
    "    \n",
    "    def get_vertices(self):\n",
    "        \"\"\" Get a list of all vertices in the graph \"\"\"\n",
    "        return list(self.G.keys())\n",
    "\n",
    "    def get_edges(self):\n",
    "        \"\"\" Return a list of edges in the graph.  Each edge is a tuple (u,v) \"\"\"\n",
    "        edges = []\n",
    "        for u in self.G:\n",
    "            for v in self.G[u]:\n",
    "                edges.append((u,v))\n",
    "        return edges\n",
    "\n",
    "    def num_vertices(self):\n",
    "        \"\"\" Return the number of vertices in the graph \"\"\"\n",
    "        return len(self.G)\n",
    "\n",
    "    def num_edges(self):\n",
    "        \"\"\" Return the number of edges in the undirected graph \"\"\"\n",
    "\n",
    "        total = 0\n",
    "        for v in self.G:\n",
    "            total += self.deg(v)\n",
    "\n",
    "        return total // 2\n",
    "\n",
    "    def deg(self,v):\n",
    "        \"\"\" What is the degree of vertext v?  i.e., how many \n",
    "        other vertices are adjacent \"\"\"\n",
    "        return len(self[v])\n",
    "\n",
    "    def degree_distribution(self):\n",
    "        \"\"\" Compute the degree distribution of the graph \n",
    "        Return a dictionary (key=degree, value=# vertices of that degree. \"\"\"\n",
    "        dd = {}\n",
    "        for v in self.G:\n",
    "            degree = self.deg(v)\n",
    "            dd[degree] = dd.get(degree,0) + 1\n",
    "        return dd\n",
    "\n",
    "    def toDF(self,columns=['u', 'v']):\n",
    "        \"\"\" Convert the graph to a pandas dataframe representation \"\"\"\n",
    "        df = pd.DataFrame(columns = columns)\n",
    "        for (u,v) in self.get_edges():\n",
    "            df = df.append({columns[0]:u, columns[1]:v}, ignore_index=True)\n",
    "        return df\n",
    "\n",
    "    def fromDF(self, df, columns=['u', 'v']):\n",
    "        \"\"\" Convert from a pandas dataframe with two columns \n",
    "        identifying the vertices.  Each row is an edge. \"\"\"\n",
    "        edges = list(zip(df[columns[0]], df[columns[1]]))\n",
    "        for u,v in edges:\n",
    "            self.add_edge(u,v)\n",
    "\n",
    "    def visualize(self, fig = 1, directed=False):\n",
    "        \"\"\" Render the graph using networkx library \"\"\"\n",
    "        \n",
    "        nx_graph = nx.Graph()\n",
    "        \n",
    "        for vertex1 in self.get_vertices():\n",
    "            for vertex2 in self.G[vertex1]:\n",
    "                dist = L2Distance(findCentroid(vertex1), findCentroid(vertex2))\n",
    "                nx_graph.add_edge(vertex1, vertex2, weight=(dist//65))\n",
    "\n",
    "        positions3d = {}\n",
    "        for color in self.get_vertices():\n",
    "            positions3d[color] = findCentroid(color)\n",
    "        \n",
    "        positions2d = {}\n",
    "        for key, value in positions3d.items():\n",
    "            positions2d[key] = threeDToTwoD(value)\n",
    "            \n",
    "        colorMap = {}\n",
    "        for color in self.get_vertices():\n",
    "            colorMap[color] = color\n",
    "        \n",
    "        plt.figure(figsize=(22, 22))\n",
    "        nx.draw(nx_graph, pos=positions2d, with_labels=True, node_color=[colorMap[node] for node in nx_graph.nodes()], \n",
    "                node_size=1200, font_size=8, width=[d['weight'] for u,v,d in nx_graph.edges(data=True)])\n",
    "        plt.show()\n",
    "       \n",
    "\n",
    "    def subgraph(self,V):\n",
    "        \"\"\" Find the subgraph consisting only of the specified \n",
    "        vertices and the edges that occur between those vertices \"\"\"\n",
    "        sub = Graph()\n",
    "        \n",
    "        # Add vertices\n",
    "        for u in V:\n",
    "            sub.add_vertex(u)\n",
    "            \n",
    "        # Add edges\n",
    "        for u in V:\n",
    "            for v in V:\n",
    "                if v in self[u]:\n",
    "                    sub.add_edge(u,v)\n",
    "        return sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d32ee",
   "metadata": {},
   "source": [
    "#### Alice Responce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33495571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Distance between guesses and centroids for each color Bob guessed\n",
    "bobCentroids = [findCentroid(color[0]) for color in bobGuesses]\n",
    "distanceBetweenGuessesAndCentroids = [L2Distance(color1, color2) for color1, color2 \n",
    "                                      in zip(bobCentroids, aliceTestColors)]\n",
    "\n",
    "colorPositions = np.arange(len(bobGuesses))\n",
    "\n",
    "for i, (color, number) in enumerate(zip(bobGuesses, distanceBetweenGuessesAndCentroids)):\n",
    "    plt.bar(colorPositions[i], number)\n",
    "\n",
    "plt.xticks(colorPositions, bobGuesses, rotation = 90)\n",
    "\n",
    "plt.xlabel('Color')\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title(\"Euclidean Distance between Centroid of Bob's Guesses and Alice's Values (in order of guesses)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Graph of all (relevant) colors and distance between centroids as edges\n",
    "\n",
    "colorGraph = Graph()\n",
    "\n",
    "# Get all unique colors from the dataframe by just taking the last word in name (ie. purpulish blue becomes blue)\n",
    "uniqueColors = list(colorsDF['Color Name'].unique())\n",
    "uniqueColors = [color.split()[len(color.split())-1] for color in uniqueColors if color != '']\n",
    "uniqueColors = list(dict.fromkeys(uniqueColors))\n",
    "\n",
    "# Series with color names and their frequencies in the dataset\n",
    "colorFreq = colorsDF['Color Name'].value_counts()\n",
    "\n",
    "# Sorting out all colors with a frequency below 5 (irrelvant colors)\n",
    "illegalColors = []\n",
    "for c, num in colorFreq.items():\n",
    "    if num < 5:\n",
    "        illegalColors.append(c)\n",
    "    \n",
    "    \n",
    "uniqueColors = [color for color in uniqueColors if isColor(color)]\n",
    "for color in illegalColors:\n",
    "    if color in uniqueColors:\n",
    "        uniqueColors.remove(color)\n",
    "        \n",
    "\n",
    "# add all remaining colors to graph\n",
    "for color in uniqueColors:\n",
    "    colorGraph.add_vertex(color)\n",
    "    for color2 in uniqueColors:\n",
    "        if color2 != color:\n",
    "            colorGraph.add_edge(color, color2)\n",
    "\n",
    "colorGraph.visualize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fff59",
   "metadata": {},
   "source": [
    "## Going Above and Beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658010a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostFreqColors():\n",
    "    \n",
    "    \"\"\"\n",
    "    Maps the most frequently appearing colors\n",
    "    \"\"\"\n",
    "\n",
    "    # Get only relevant colors (take last word of color name then filter out frequencies under 50)\n",
    "    colorsDF['Color Name'] = colorsDF['Color Name'].apply(lambda x: x.split()[-1] if x else '')\n",
    "    colorFreq = colorsDF['Color Name'].value_counts()\n",
    "    colorFreqFiltered = colorFreq[colorFreq > 50]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colorFreqFiltered.plot(kind='bar')\n",
    "    plt.title('Frequency of Colors')\n",
    "    plt.xlabel('Color')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "mostFreqColors()\n",
    "print(\"Demonstrates a bias toward popular colors\")\n",
    "\n",
    "\n",
    "def plotMisclassColors():\n",
    "    \"\"\"\n",
    "    Maps the most frequently misclassified colors\n",
    "    \"\"\"\n",
    "    misclassColors = {}\n",
    "\n",
    "    testColors = []\n",
    "    testColors.extend([generateRandomColor() for _ in range(250)])\n",
    "\n",
    "    guesses = rgbListToColorList(knnModel, testColors)\n",
    "\n",
    "    totalGuesses = len(testColors)\n",
    "    correctGuesses = 0\n",
    "\n",
    "    # counting the color appearance count and misclassifcation count in value\n",
    "    for rgbVal, color in zip(testColors, guesses):\n",
    "        if isCorrectColor(color, rgbVal, 120):\n",
    "            continue\n",
    "        else:\n",
    "            if color in misclassColors:\n",
    "                misclassColors[color] += 1\n",
    "            else:\n",
    "                misclassColors[color] = 1\n",
    "\n",
    "    misclassColorsSorted = dict(sorted(misclassColors.items(), key=lambda item: item[1], reverse = True))\n",
    "    misclassColorsFiltered = {key: value for key, value in misclassColorsSorted.items() if value > 1}\n",
    "\n",
    "    plt.bar(list(misclassColorsFiltered.keys()), list(misclassColorsFiltered.values()))\n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "    # Adding labels\n",
    "    plt.xlabel('Colors')\n",
    "    plt.ylabel('Number of Misclassifcations')\n",
    "    plt.title('Most Often Misclassified Colors')\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "    \n",
    "plotMisclassColors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b32f1",
   "metadata": {},
   "source": [
    "## Relection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c2acd",
   "metadata": {},
   "source": [
    "This project was beneficial for me in understanding the critical concepts of supervised learning. By using KNN, I understood how data is processed, how models are deployed, how to tune the model's hyperparameters, and how to use metrics to evaluate performance. Preprocessing the data took some time as I had to remove overly specific color names by filtering out adjectives such as 'saturated', 'soft', and 'muted'. Deploying the model was also a valuable task as I had never used Sci-Kit Learn before and found how easy it was to build the model. The hyperparamiterzation of K was somewhat challenging as I had to use an n-fold cross-validation metric to find which value of K minimized the total Euclidian distance between RGB colors and their centroids. That value of K tended to be relatively low (most often 3). Finally, the metrics I mapped helped confirm my value of K as the F1 score and accuracy score often followed the total distance measure for each value of K.\n",
    "\n",
    "My biggest challenge was creating my own distance metrics. The Sci-Kit Learn library is not practical in testing this model because if we generate random values to test the model with, we have no answers (or ground truths) to compare them to. I found the dataset had too many unique colors and a significantly unbalanced distribution of colors (ie far more greens and blues than reds and oragnes). I tried to fix this issue using Sci-Kit's startified K fold validation (which takes test sets that uphold percecntage distributions of each color) but my accuracy remained too low (around 0.38 or 38%). For the reasons listed above I belive Sci Kit is fundamentally somewhat flawed for this problem.\n",
    "\n",
    "Therefore, I generated my own method of creating ground truth by making a function that returns True if the distance between a color and its centroid was under a certain threshold (usually 80). I found the threshold of 80 to be effective through trial and error. I went on an RGB visualization site, plugged in various colors, and calculated their Euclidian distances. In my opinion, any 2 colors with a distance of 80 or less could undeniably be categorized as the same color. With a distance of 90 or greater, that assertion can be questioned in some instances. \n",
    "\n",
    "Therefore, I generated 300 random values. Determined their groundtruths. Then, I used that information to calculate a more accurate accuracy, F1, recall, and precision score than Sci-Kit Learn, which has no real knowledge of the circumstances. \n",
    "\n",
    "Another challenge I faced was determining how many colors to filter out from Alice's graph. It was a tradeoff between readibility of the vertexes and their labels and the completness of the graph.\n",
    "\n",
    "\n",
    "For future iterations of this project, I would recommend having students manually implement KNN. I did it to begin before the lecture about Sci-Kit Learn, and it worked nearly as well. I deleted it because the assignment was to use Python libraries, but it is a relatively easy algorithm to implement, and I feel it would give students a better understanding of what is going on behind the scenes. I also think it would give a more satisfying result to students when it works as they would feel they have more ownership of it rather than typing 3 lines calling Python libraries. Furthermore, it would allow students to hyperparameterize another variable: the distance function as well as K. This was the most interesting part of the project for me, so having another parameter to optimize would be fun. Lastly, it would lead to further interesting visualizations based on Euclidean, Hamming, Manhatten, etc.; distance functions students would implement. They could map performance based on each function with various K values and ensemble them to see what is truly best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefcffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
